{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5, Question 6: Data Transformation\n",
    "\n",
    "**Points: 20**\n",
    "\n",
    "Transform and engineer features from the clinical trial dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10000 patients\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import utilities\n",
    "from q3_data_utils import (\n",
    "    load_data,\n",
    "    clean_data,\n",
    "    transform_types,\n",
    "    create_bins,\n",
    "    fill_missing,\n",
    ")\n",
    "\n",
    "df = load_data(\"data/clinical_trial_raw.csv\")\n",
    "print(f\"Loaded {len(df)} patients\")\n",
    "\n",
    "\n",
    "# Prewritten visualization functions for transformation analysis\n",
    "def plot_distribution(series, title, figsize=(10, 6)):\n",
    "    \"\"\"\n",
    "    Create a histogram of a numeric series.\n",
    "\n",
    "    Args:\n",
    "        series: pandas Series with numeric data\n",
    "        title: Chart title\n",
    "        figsize: Figure size tuple\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    series.hist(bins=30)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_value_counts(series, title, figsize=(10, 6)):\n",
    "    \"\"\"\n",
    "    Create a bar chart of value counts.\n",
    "\n",
    "    Args:\n",
    "        series: pandas Series with value counts\n",
    "        title: Chart title\n",
    "        figsize: Figure size tuple\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    series.plot(kind=\"bar\")\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Type Conversions (5 points)\n",
    "\n",
    "1. Convert 'enrollment_date' to datetime using the `transform_types()` utility\n",
    "2. Convert categorical columns ('site', 'intervention_group', 'sex') to category dtype\n",
    "3. Ensure all numeric columns are proper numeric types\n",
    "4. Display the updated dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Data Types:\n",
      "patient_id                   float64\n",
      "age                            int64\n",
      "sex                         category\n",
      "bmi                          float64\n",
      "enrollment_date       datetime64[ns]\n",
      "systolic_bp                  float64\n",
      "diastolic_bp                 float64\n",
      "cholesterol_total            float64\n",
      "cholesterol_hdl              float64\n",
      "cholesterol_ldl              float64\n",
      "glucose_fasting              float64\n",
      "site                        category\n",
      "intervention_group          category\n",
      "follow_up_months               int64\n",
      "adverse_events                 int64\n",
      "outcome_cvd                  float64\n",
      "adherence_pct                float64\n",
      "dropout                      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# TODO: Type conversions\n",
    "# 1. Use transform_types() to convert enrollment_date to datetime\n",
    "# 2. Convert categorical columns ('site', 'intervention_group', 'sex') to category dtype\n",
    "# 3. Ensure all numeric columns are proper numeric types\n",
    "# 4. Display the updated dtypes using df.dtypes\n",
    "type_map = {\n",
    "    \"enrollment_date\": \"datetime\",  # use 'datetime' to match transform_types()\n",
    "    \"site\": \"category\",\n",
    "    \"intervention_group\": \"category\",\n",
    "    \"sex\": \"category\",\n",
    "}\n",
    "\n",
    "df = transform_types(df, type_map)\n",
    "\n",
    "cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "for col in cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "print(\"Updated Data Types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Feature Engineering (8 points)\n",
    "\n",
    "Create these new calculated columns:\n",
    "\n",
    "1. `cholesterol_ratio` = cholesterol_ldl / cholesterol_hdl\n",
    "2. `bp_category` = categorize systolic BP:\n",
    "   - 'Normal': < 120\n",
    "   - 'Elevated': 120-129\n",
    "   - 'High': >= 130\n",
    "3. `age_group` using `create_bins()` utility:\n",
    "   - Bins: [0, 40, 55, 70, 100]\n",
    "   - Labels: ['<40', '40-54', '55-69', '70+']\n",
    "4. `bmi_category` using standard BMI categories:\n",
    "   - Underweight: <18.5\n",
    "   - Normal: 18.5-24.9\n",
    "   - Overweight: 25-29.9\n",
    "   - Obese: >=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cholesterol_ratio\n",
      "0           0.745455\n",
      "1           1.844828\n",
      "2           1.464286\n",
      "3           1.857143\n",
      "4           0.961538\n"
     ]
    }
   ],
   "source": [
    "# TODO: Calculate cholesterol ratio\n",
    "df[\"cholesterol_ratio\"] = df[\"cholesterol_ldl\"] / df[\"cholesterol_hdl\"]\n",
    "print(df[[\"cholesterol_ratio\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   systolic_bp bp_category\n",
      "0        123.0    Elevated\n",
      "1        139.0        High\n",
      "2        123.0    Elevated\n",
      "3        116.0      Normal\n",
      "4         97.0      Normal\n"
     ]
    }
   ],
   "source": [
    "# TODO: Categorize blood pressure\n",
    "df[\"bp_category\"] = np.where(\n",
    "    df[\"systolic_bp\"] < 120,\n",
    "    \"Normal\",\n",
    "    np.where(df[\"systolic_bp\"] < 130, \"Elevated\", \"High\"),\n",
    ")\n",
    "print(df[[\"systolic_bp\", \"bp_category\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The `create_bins()` function has an optional `new_column` parameter. If you don't specify it, the new column will be named `{original_column}_binned`. You can use `new_column='age_group'` to give it a custom name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age age_group\n",
      "0   80       70+\n",
      "1   80       70+\n",
      "2   82       70+\n",
      "3   95       70+\n",
      "4   95       70+\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create age groups\n",
    "df = create_bins(\n",
    "    df,\n",
    "    column=\"age\",\n",
    "    bins=[0, 40, 55, 70, 100],\n",
    "    labels=[\"<40\", \"40-54\", \"55-69\", \"70+\"],\n",
    "    new_column=\"age_group\",\n",
    ")\n",
    "\n",
    "print(df[[\"age\", \"age_group\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    bmi bmi_category\n",
      "0  29.3   Overweight\n",
      "1  26.2   Overweight\n",
      "2  26.2   Overweight\n",
      "3  25.4   Overweight\n",
      "4  26.2   Overweight\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create BMI categories\n",
    "df = clean_data(df, sentinel_value=-999)  # Clean sentinel values\n",
    "df[\"bmi\"] = df[\"bmi\"].replace([\"NA\", \"None\", -1, 0], np.nan)\n",
    "df = fill_missing(df, \"bmi\", strategy=\"median\")\n",
    "\n",
    "df = create_bins(\n",
    "    df,\n",
    "    column=\"bmi\",\n",
    "    bins=[0, 18.5, 24.9, 29.9, 100],\n",
    "    labels=[\"Underweight\", \"Normal\", \"Overweight\", \"Obese\"],\n",
    "    new_column=\"bmi_category\",\n",
    ")\n",
    "\n",
    "print(df[[\"bmi\", \"bmi_category\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: String Cleaning (2 points)\n",
    "\n",
    "If there are any string columns that need cleaning:\n",
    "1. Convert to lowercase\n",
    "2. Strip whitespace\n",
    "3. Replace any placeholder values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String Columns Cleaned: ['bp_category']\n"
     ]
    }
   ],
   "source": [
    "# TODO: String cleaning\n",
    "string_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "for col in string_cols:\n",
    "    df[col] = df[col].str.lower()\n",
    "    df[col] = df[col].str.strip()\n",
    "    df[col] = df[col].replace(\n",
    "        [\"na\", \"none\", \"missing\", \"n/a\", \"null\", \"nan\", \"\"], np.nan\n",
    "    )\n",
    "\n",
    "print(\"String Columns Cleaned:\", list(string_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: One-Hot Encoding (5 points)\n",
    "\n",
    "Create dummy variables for categorical columns:\n",
    "1. One-hot encode 'intervention_group' using `pd.get_dummies()`\n",
    "2. One-hot encode 'site'\n",
    "3. Drop the original categorical columns\n",
    "4. Show the new shape and column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New DataFrame shape: (10000, 80)\n",
      "New columns after encoding:\n",
      "['patient_id', 'age', 'sex', 'bmi', 'enrollment_date', 'systolic_bp', 'diastolic_bp', 'cholesterol_total', 'cholesterol_hdl', 'cholesterol_ldl', 'glucose_fasting', 'follow_up_months', 'adverse_events', 'outcome_cvd', 'adherence_pct'] ...\n"
     ]
    }
   ],
   "source": [
    "# TODO: One-hot encoding\n",
    "categorical_cols = [\"intervention_group\", \"site\"]\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=False)\n",
    "\n",
    "print(\"New DataFrame shape:\", df_encoded.shape)\n",
    "print(\"New columns after encoding:\")\n",
    "print(df_encoded.columns.tolist()[:15], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Save Transformed Data\n",
    "\n",
    "Save the fully transformed dataset to `output/q6_transformed_data.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save transformed data\n",
    "# df_transformed.to_csv('output/q6_transformed_data.csv', index=False)\n",
    "df_transformed = df_encoded\n",
    "df_transformed.to_csv(\"output/q6_transformed_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
